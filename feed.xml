<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-09-24T21:27:24+05:30</updated><id>/feed.xml</id><title type="html">blank</title><subtitle>Hello! I’m a post-doctoral research fellow, working with IDIA and NRAO. I’m primarily interested in developing new algorithms and methods to visualize, calibrate, and image the (astronomically) large data sets that a modern radio telescope produces.
</subtitle><entry><title type="html">COVID in the news</title><link href="/blog/2021/covid-news/" rel="alternate" type="text/html" title="COVID in the news" /><published>2021-09-24T00:00:00+05:30</published><updated>2021-09-24T00:00:00+05:30</updated><id>/blog/2021/covid-news</id><content type="html" xml:base="/blog/2021/covid-news/">&lt;p&gt;I remember traveling from India to South Africa in early February 2020 and
hearing whispers of some ultra-deadly mystery virus. A few weeks after I landed
in Cape Town, the lockdowns started world over and the panic was pretty
palpable. Back in India there was a similar sense of panic during the second
wave in mid-2021, which was pretty deadly and overloaded
healthcare systems to the point of breaking in many cases (even though the
government &lt;a href=&quot;https://www.bbc.com/news/world-asia-india-57911638&quot;&gt;seems to think
otherwise&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;I got curious about how the news tracked this perceived panic, and I started by
looking at newspaper headlines. The way I planned to do this was to scrape
every headline published by the newspaper since January 2020 and count the
number of times &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;covid&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coronavirus&lt;/code&gt; was mentioned. To this end, I picked
the &lt;a href=&quot;https://indianexpress.com/&quot;&gt;Indian Express&lt;/a&gt; for no good reason other than
that I was able to find the URL for their archives first.&lt;/p&gt;

&lt;p&gt;The analysis I described above, &lt;em&gt;i.e.,&lt;/em&gt; counting the number of occurences of
the two keywords, is fairly simplistic and will ignore a lot of actual news
stories about the virus. For example any geographical or numerical indicators
in the headline, like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;200 new cases reported in Chennai&lt;/code&gt; would have been
missed by this method.  However devising a more complete and accurate heuristic
would have taken more time than I had to dedicate to this, so I left it as is.
I figured simply counting the number of times &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;covid&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;coronavirus&lt;/code&gt; (case
insensitive) would serve as a good proxy for how intense the reporting was at
any point.&lt;/p&gt;

&lt;p&gt;All the code, and the dataset of headlines with a timestamp, are stored in
&lt;a href=&quot;https://github.com/Kitchi/covid-news&quot;&gt;this&lt;/a&gt; GitHub repository (fair warning,
the code is messy!).&lt;/p&gt;

&lt;h3 id=&quot;grabbing-headlines&quot;&gt;Grabbing headlines&lt;/h3&gt;

&lt;p&gt;In order to grab the headlines that I needed, I had to (a) figure out the
generic URL for Indian Express archived news stories and (b) figure out how to
scrape the headlines from the webpage. Turns out, the first part wasn’t so
hard. The website has a &lt;a href=&quot;https://indianexpress.com/section/india/&quot;&gt;section&lt;/a&gt; for
all regional stories about India that conveniently shows the headlines and
summary of all the news articles published at a national level.&lt;/p&gt;

&lt;p&gt;The second part required some code wrangling, but also ended up being fairly
(and happily!) straightforward for the most part.&lt;/p&gt;

&lt;p&gt;I used a combination of
&lt;a href=&quot;https://docs.python-requests.org/en/master/index.html&quot;&gt;requests&lt;/a&gt; and
&lt;a href=&quot;https://beautiful-soup-4.readthedocs.io/en/latest/&quot;&gt;BeautifulSoup&lt;/a&gt; to retrieve
and parse the HTML contents of the webpage.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BeautifulSoup&lt;/code&gt; is an incredible tool to parse HTML content because it builds a
tree from the HTML document and allows you to walk the tree in a very intuitive
way to find various elements you need. In this case, the headlines were all
encased in a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;h2&amp;gt;&lt;/code&gt; tag with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&apos;class&apos;:&apos;title&apos;&lt;/code&gt; attribute. The dates were in a
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;div&amp;gt;&lt;/code&gt; tag immediately below the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;h2&amp;gt;&lt;/code&gt; tag, or in the langauage of
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BeautifulSoup&lt;/code&gt;, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;div&amp;gt;&lt;/code&gt; was the next sibling.&lt;/p&gt;

&lt;p&gt;So once I had the page URL, it was easy to get the raw HTML and then turn it
into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;soup&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;page_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;html.parser&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Hunting for the headlines and the dates was also quite intuitive, however some
amount of “cleaning” was necessary to strip out additional whitespaces etc.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h2&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;h2&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;class&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;title&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;heading&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;a&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heading&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;heading&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;heading&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findNextSibling&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;div&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;I also grabbed the number of cases per week from the
&lt;a href=&quot;https://www.ecdc.europa.eu/en/covid-19/data&quot;&gt;ECDC&lt;/a&gt; website as a comparison.
Finding this data on their website was not as difficult as I’d imagined,
although hunting for similar datasets from WHO or the Indian Government was
substantially harder, which is why I went with ECDC.&lt;/p&gt;

&lt;p&gt;Once I had the headlines, I just dumped them into a text file so I could read
it in with trust ol’ &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt;.  Scraping all the headlines I needed took a
surprising (for me!) amount of time, but running it in the background while I
did other things got me what I needed in a few hours.&lt;/p&gt;

&lt;p&gt;However one thing that I didn’t think through all that well was having a
whitespace delimited file containing headlines with whitespaces and a variable
number of words. This yielded effectively a variable number of columns that
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pandas&lt;/code&gt; had a fit over, so I had to write a simple parsing function to get the
dates and headlines out of the text file coherently. Once I had the headlines,
I constructed a saner looking &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DataFrame&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# read_file is the parsing function, look at plot_news.py in the repo
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;day&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;day&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;month&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;month&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;year&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;year&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;headline&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headline&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;my&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;month&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;year&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;I had to wrangle the ECDC data to give me a similar &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;month-year&lt;/code&gt; column, and
once that was done I simply used the ultra-useful &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;groupby&lt;/code&gt; function to figure
out how many headlines (and cases) we had per month.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c1&quot;&gt;# edf is the ECDC dataframe
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gedf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;my&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# df is the Indian Express dataframe
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;my&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;the-results&quot;&gt;The results&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/news_vs_cases.png&quot; alt=&quot;COVID news vs. number of cases&quot; width=&quot;750&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see from the plot, the blue bars are the number of news articles
about COVID per month, and the orange line is the number of cases per month.
Both these quantities have been expressed as a fraction of the total, so for
example the number of COVID cases peaked in May 2021 at 25%, meaning that
around a quarter of all total COVID cases (since January 2020) occurred in May
2021.&lt;/p&gt;

&lt;p&gt;There are a couple of things that stick out to me from this plot. The first is
that the sense of panic I felt in early 2020 is borne out by the news cycle,
with over 40% of all reports of COVID-19 occuring in March and April 2020. By
the time the first real peak rolled around in India, the news seems to have
largely settled down.&lt;/p&gt;

&lt;p&gt;The second thing is that the reporting toward the tail end of the first wave
(Nov - Dec 2020) and the peak of the second wave (Apr - May 2021) is also more
or less the same, despite the fact that India was having an objectively worse
time during the second wave, which was responsible for about 50% of all cases
in just a two month period. The reason for the under-reporting is puzzling, I’d
be interested to see what they were reporting on instead of COVID, but that’s
for another post.&lt;/p&gt;

&lt;p&gt;I’ll point out here the caveat that this little experiment was only
conducted using the headlines of Indian Express, so it may or may not be
representative of Indian print media at large. I am also keen on seeing
differences (if any) in COVID reporting depending on the political leanings of
the news outlets.&lt;/p&gt;</content><author><name></name></author><summary type="html">I remember traveling from India to South Africa in early February 2020 and hearing whispers of some ultra-deadly mystery virus. A few weeks after I landed in Cape Town, the lockdowns started world over and the panic was pretty palpable. Back in India there was a similar sense of panic during the second wave in mid-2021, which was pretty deadly and overloaded healthcare systems to the point of breaking in many cases (even though the government seems to think otherwise).</summary></entry></feed>